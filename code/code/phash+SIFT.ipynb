{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "quantitative-title",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ref: WorkSheet 7 & 8\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import re\n",
    "import csv\n",
    "rootpath='./'\n",
    "train_path = './train'\n",
    "test_path = './test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "trying-terrorist",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ref: https://www.jianshu.com/p/d787e1bd4481\n",
    "def pHash(img,leng=32,wid=32):\n",
    "    img = cv2.imread(os.path.join(rootpath,img),cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (leng, wid)) \n",
    "    dct = cv2.dct(np.float32(img))\n",
    "    dct_roi = dct[0:8, 0:8]           \n",
    "    avreage = np.mean(dct_roi)\n",
    "    phash_01 = (dct_roi>avreage)+0\n",
    "    phash_list = phash_01.reshape(1,-1)[0].tolist()\n",
    "    phash = ''.join([str(x) for x in phash_list])\n",
    "    return phash\n",
    "\n",
    "def Hamming_distance(hash1,hash2):\n",
    "    num = 0\n",
    "    for index in range(len(hash1)):\n",
    "        if hash1[index] != hash2[index]:\n",
    "            num += 1\n",
    "    return 1-num/len(hash1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sharing-favorite",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = [i for i in os.listdir(\"train\") if re.match(r'(.*?.jpg)',i)]\n",
    "test_dir = [i for i in os.listdir(\"test\") if re.match(r'(.*?.jpg)',i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "generic-cooper",
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv2.SIFT_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-thesaurus",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_all():\n",
    "    res = {}\n",
    "    for i in tqdm(train_dir):\n",
    "        res[i] = pHash(os.path.join(train_path,i))\n",
    "    return res\n",
    "hash_values = hash_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-coral",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_image: input image name\n",
    "# num: length of return\n",
    "def rank_pic_by_phash(input_img,num,hash_values):\n",
    "    p_test = pHash(os.path.join(test_path,input_img))\n",
    "    res = {}\n",
    "    for i in train_dir:\n",
    "        p_train = hash_values[i]\n",
    "        res[i] = Hamming_distance(p_test,p_train)\n",
    "    return sorted(res.items(), key = lambda x:(x[1],x[0]), reverse=True)[:num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-throw",
   "metadata": {},
   "outputs": [],
   "source": [
    "#target = rank_pic_by_phash(\"IMG5089_1.jpg\",1000,hash_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-james",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_n(img_path, target,n):\n",
    "    res = {}\n",
    "    img = cv2.imread(os.path.join(test_path,img_path),cv2.IMREAD_GRAYSCALE)\n",
    "    kp1,des1 = sift.detectAndCompute(img,None)\n",
    "    for i in target:\n",
    "        target_img = cv2.imread(os.path.join(train_path,i[0]),cv2.IMREAD_GRAYSCALE)\n",
    "        kp2,des2 = sift.detectAndCompute(target_img,None)\n",
    "        # FLANN parameters and initialize\n",
    "        FLANN_INDEX_KDTREE = 1\n",
    "        index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "        search_params = dict(checks=50)   # or pass empty dictionary\n",
    "        flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "        if(len(kp1)>=2 and len(kp2)>=2):\n",
    "            # Matching descriptor using KNN algorithm\n",
    "            matches = flann.knnMatch(des1, des2, k=2) \n",
    "            # Create a mask to draw all good matches\n",
    "            matchesMask = []\n",
    "            # Store all good matches as per Lowe's Ratio test.\n",
    "            good = []\n",
    "            for m,n in matches:\n",
    "                if m.distance < 0.7*n.distance:\n",
    "                    good.append(m)\n",
    "                    matchesMask.append([1,0]) # Match\n",
    "                else:\n",
    "                    matchesMask.append([0,0]) # Mismatch\n",
    "            # Print total number of good matches between two images\n",
    "            res[i[0]] = len(good)/len(matchesMask)\n",
    "    return sorted(res.items(), key = lambda x:(x[1],x[0]), reverse=True)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informative-blade",
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_50 = find_top_n(\"IMG5089_1.jpg\",target,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-density",
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-essay",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best(top_n,img_path):\n",
    "    for i in top_n:\n",
    "        img = cv2.imread(os.path.join(test_path,img_path),0)\n",
    "        candidate = cv2.imread(os.path.join(train_path,i[0]),0)\n",
    "        kp1, des1 = sift.detectAndCompute(img,None)\n",
    "        kp2, des2 = sift.detectAndCompute(candidate,None)\n",
    "        # FLANN parameters and initialize\n",
    "        FLANN_INDEX_KDTREE = 1\n",
    "        index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "        search_params = dict(checks=50)   # or pass empty dictionary\n",
    "        flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "        # Matching descriptor using KNN algorithm\n",
    "        matches = flann.knnMatch(des1,des2,k=2)\n",
    "        # Create a mask to draw all good matches\n",
    "        matchesMask = []\n",
    "        # Store all good matches as per Lowe's Ratio test.\n",
    "        good = []\n",
    "        for m,n in matches:\n",
    "            if m.distance < 0.7*n.distance:\n",
    "                good.append(m)\n",
    "                matchesMask.append([1,0]) # Match\n",
    "            else:\n",
    "                matchesMask.append([0,0]) # Mismatch\n",
    "        MIN_MATCH_NUM = 4\n",
    "        if len(good)> MIN_MATCH_NUM:\n",
    "            ptsA = np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1,1,2)\n",
    "            ptsB = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1,1,2)\n",
    "            H, status = cv2.findHomography(ptsA, \n",
    "                                           ptsB, \n",
    "                                           cv2.RANSAC, \n",
    "                                           ransacReprojThreshold = 5, \n",
    "                                           maxIters = 10) # try to change maxIters and see the effect\n",
    "            success = status.ravel().tolist()\n",
    "            #Threshold to avoid match wall\n",
    "            if(success.count(1)/len(good) > 0.15):\n",
    "                return i[0]\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-wagner",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find_best(top_50,\"IMG5089_1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-companion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-superior",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv(\"train.csv\")\n",
    "image_names = pd.read_csv(\"imagenames.csv\").values.flatten()\n",
    "def main_func(hash_num=1000,flann_num=50):\n",
    "    errors = []\n",
    "    for test_file in tqdm(image_names):\n",
    "        test_file+=\".jpg\"\n",
    "        pHash_top = rank_pic_by_phash(test_file,hash_num,hash_values)\n",
    "        flann_top = find_top_n(test_file,pHash_top,flann_num)\n",
    "        best_match = find_best(flann_top,test_file)\n",
    "        if best_match:\n",
    "            best_match = re.sub(\".jpg\",\"\",best_match)\n",
    "            x = train_csv.loc[train_csv[\"id\"]==best_match][\"x\"].values[0]\n",
    "            y = train_csv.loc[train_csv[\"id\"]==best_match][\"y\"].values[0]\n",
    "            f = open('test.csv','a')\n",
    "            writer = csv.writer(f)\n",
    "            test_file = re.sub(\".jpg\",\"\",test_file)\n",
    "            writer.writerow((test_file,x,y))\n",
    "            f.close()\n",
    "        else:\n",
    "            errors.append(test_file)\n",
    "            print(test_file)\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-wound",
   "metadata": {},
   "outputs": [],
   "source": [
    "err = main_func(hash_num=1000,flann_num=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-battlefield",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
